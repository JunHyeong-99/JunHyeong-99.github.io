---
layout: post
title: Survey 보고서
author: John Doe
tags: article, nextjs, js
---

# 공학작문과 발표 과제물 #3 Survey 보고서

## TSP 문제 해결을 위한 Algorithms 비교

### 요약
TSP(Traveling Salesman Problem)를 해결하는 Uninformed Search Algorithm인 BFS, DFS, Uniform-cost Search, Informed Search Algorithm인 Greedy Best-first, A* , Local Search Algorithm인  Steepest Ascent, Stochastic, First-choice, Random-restart Algorithm에 대해 설명하고 비교한 글이다. 

### 서론

3학년 전공선택 과목인 인공지능 수업을 수강 중 배운 문제의 여러 솔루션 Algorithm을 배워 각 Algorithm의 설명, 성능, 장단점을 비교하고자 작성하게 되었다.

### 본론

TSP[^tsp] 문제를 해결하는 Algorithm으로 먼저 Uninformed Search Algorithm을 살펴볼 것이다 Uninformed Search란 현재까지 진행된 정보만 이용해서 탐색하는 Algorithm이다. 이와 반대로 Informed Search Algorithm도 있는데 이는 현재까지 진행된 정보만을 이용하는 것이 아닌 미래에 수행될 정보를 예측해서 수행하는 Algorithm이다.

먼저 BFS 알고리즘은 흔히 알고 있는 넓이 우선 탐색 방식이다. 다음 탐색의 후보가 되는 노드의 집합을 frontier라고 하겠다. TSP에서 인접한 도시들을 방문한 적이 없거나 frontier에 이미 들어가 있지 않는 경우 노드로 frontier에 넣고 FIFO(first in first out) 방식으로 frontier에서 노드를 꺼내서 frontier가 Empty 해지거나 Goal-test를 성공할 때까지 loop를 돌며 탐색하게 된다. 여기서 중요한 부분은 탐색 시간을 줄이기 위해 새로운 노드를 frontier에서 pop 하고 Goal-test를 하는 것이 아닌 frontier에 노드를 넣기 전에 Goal-test를 하며 한 depth를 탐색할 시간을 줄여 주어야 한다. depth가 깊지 않으면 시간의 차이가 무의미하게 작지만 depth가 깊어질 수록 시간의 차이가 아래 표와 같이 많이 나기 때문이다.

![img1](https://github.com/JunHyeong-99/JunHyeong-99.github.io/assets/64734115/76ffcc79-d85b-4a4b-ade4-57e12c12f79f)
[^tsp]: TSP 문제란 그래프의 처음 시작 노드에서 모든 노드를 거쳐서 시작 노드로 돌아오는 최소 cost 경로를 찾는 문제이다.

다음으로 Uniform-cost Search Algorithm은 BFS Algorithm의 FIFO 방식 대신 frontier에서 노드를 pop 하는 방식으로 Priority queue를 사용하는 Algorithm이다. BFS Algorithm과 다르게 인접 노드를 frontier에 넣을 때 redundant path를 허용한다. 즉 frontier에 이미 있는 노드라도 cost가 더 낮다면 기존에 frontier에 있던 노드를 삭제하고 cost가 더 낮은 노드를 frontier에 넣어준다. Uniform-cost Search Algorithm의 Goal-test는 frontier에서 pop을 한 후 수행하게 된다. 만약 Goal-test를 frontier에 노드를 넣기 전에 한다면 redundant path에 의한 더 좋은 cost를 찾을 가능성을 잃어 버리기 때문에 least-cost를 보장해주기 위해서이다.

다음은 Depth-first Search Algorithm은 깊이 우선 탐색 알고리즘으로 소개할 알고리즘에서는 무한 루프를 피하기 위해 frontier에 노드를 넣기 전에 자신의 ancestor에 있는  노드인 경우 frontier에만 넣지 않는다. 즉 방문한 노드에 포함된 노드라도 ancestor에만 없으면 frontier에 노드를 추가한다. 또 redundant path를 허용하게 된다. 

알고리즘을 평가하는 기준으로 Time, Space, Complete, Optimal으로 둘 수 있다. 여기서 Time은 시간 복잡도 Space는 공간 복잡도 Complete는 현재 지점에서 목표 지점까지의 path를 찾을 수 있는가? Optimal은 가장 최소 cost의 path를 찾을 수 있는가?이다.
아래 표로 정리했다.

![img2](https://github.com/JunHyeong-99/JunHyeong-99.github.io/assets/64734115/12e4cb45-72bf-4bea-9ea1-c883cdae586d)

b: branching factor
d: depth of solution
m:maximum depth of the search tree
 a:complete if b is finite
ε: step cost
 b :complete if step cost >= ε for positive ε
 c: optimal if step costs are all identical
[1]

다음으로 Informed Search Algorithm을 알아보자 Informed Search Algorithm은 평가 함수로 f(n) = g(n) + h(n)을 사용한다 g(n)은 시작 노드에서 현재 노드까지의 거리를 뜻하고 h(n)은 Heuristic 함수로 현재에서 목표지점까지의 cost 추정치를 뜻한다. Informed Search Algorithm에서는 평가 함수의 값으로 우선순위를 정해서 탐색하게 된다.


Informed Search Algorithm에는 Greedy Best-first Search, A* Algorithm이 있다 이 두 개의 Algorithm 모두 BFS 기반으로 동작한다. Greedy Best-first Search Algorithm은 g(n) = 0으로 두고 h(n)의 계산으로만 Algorithm이 수행된다. 즉 과거의 cost는 고려하지 않은 채 미래의 목표지점까지의 예측 cost만 고려하여 탐색하게 된다. 반면 A* Algorithm은 g(n),  h(n) 둘 다 고려하여 수행된다. 두 Algorithm 모두 h(n)을 현재 지점에서 목표지점 까지의 직선 거리를 사용한다. 

![img3](https://github.com/JunHyeong-99/JunHyeong-99.github.io/assets/64734115/4887d270-2906-40ff-9879-78fd645cada3)

다음으로 Local Search Algorithms에 대해 알아보자 Local Search Algorithms을 TSP에 적용하는 방법은 시작 노드에서 순서대로 노드를 선택해 가며 솔루션을 구하는 방법이 아니라 최소 cost를 가지는 path는 아니지만 모든 도시를 한 번씩 방문한 path(complete configuration)를 만들어 Initial Configuration로 이용하여 만들어진 path를 반복하며 각 알고리즘에 맞는 다양한 방법으로 경로를 수정해 가며 최소 cost를 가지는 경로를 구한다 방식으로 적용된다. 이제 각 알고리즘을 알아보자.

Steepest Ascent Hill Climbing Algorithm에 대해 알아보자 먼저 MAKE-NODE 함수로 Initial Configuration을 만든다. 그후 현재 노드의 후임자 중에서 평가 함수의 값이 가장 높은 neighbor을 찾아  neighbor의 값과 현재 값을 비교해서 neighbor 값이 작으면 현재를 neighbor로 바꾸어 주고 현재의 값이 더 작으면 함수를 종료하고 현재 Configuration을 반환한다. 하지만 이 알고리즘은 local maximum을 피하기 위한 알고리즘이 전혀 적용시키지 않은 알고리즘이다. 

local maximum을 피하기 위한 알고리즘을 적용한 알고리즘은 크게 Stochastic Hill Climbing, First-choice Hill Climbing, Random-restart Hill Climbing 알고리즘이 있다. 이제 각 알고리즘에 대해 알아보자. 

Stochastic Hill Climbing Algorithm은 현재 노드의 후임자 중에서 평가 함수의 값이 가장 높은 노드를 선택하는 Steepest Ascent Hill Climbing 방법과 다르게 평가 함수의 값이 높을수록 높은 확률을 부여해 낮은 확률로 평가 함수의 값이 낮은 노드를 선택할 수 있게 하여 local maximum 문제를 피하는 알고리즘이다. 

First-choice Hill Climbing Algorithm은 후임자의 수가 많아지는 후임자를 다 정렬하기에 부담이 있어 후임자를 만드는 과정에서 현재 상태의 값보다 큰 값을 가지는 후임자가 나타나는 경우 바로 현재 상태를 바꿔주는 알고리즘이다. 이 알고리즘도 가장 높은 평가 함수를 가지는 후임자를 선택하지 않는다는 점에서 local maximum 문제를 어느 정도 피할 수 있다.

Random-restart Hill Climbing Algorithm은 Initial Configuration을 다시 설정해서 여러 번 수행하는 알고리즘이다 이렇게 수행했을 때 시작 노드가 달라지게 되므로 서로 다른 local maximum을 구할 확률이 높아지고 이렇게 되면 구해진 여러 local maximum 중 global maximum이 될 확률이 높아진다는 장점이 있다.

![img4](https://github.com/JunHyeong-99/JunHyeong-99.github.io/assets/64734115/a4cee059-2227-4d39-bdc2-e631b2870a53)


### 결론

TSP라는 여러 분야에 응용되어 적용될 수 있는 문제의 여러 해결 방법을 조사해 보고 비교해 보았다. 주어진 TSP 문제의 특성에 따라 효율적인 알고리즘이 다르다고 생각하며, global maximum과 local maximum이 큰 차이가 없고 공간이 큰 문제의 상황에서는 메모리와 시간을 절약하기 위해 Local Search Algorithms 중 하나를 선택해서 해결하고 공간이 작고 global maximum과 local maximum의 차이가 크고 중요한 문제인 경우 Informed Search Algorithm를 이용해서 문제를 해결하면 좋겠다는 생각이 들었다. 또  Local Search Algorithms의 local maximum문제를 더 효율적으로 해결하는 또 다른 다양한 방법이 있을 거 같아 흥미로웠다.

### 참고문헌

[1]artificial intelligence: a modern approach, 4th ed. stuart russell and peter Norvig, prentice hall, 2020




